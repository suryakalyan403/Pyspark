{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import  StructType,StructField, StringType, IntegerType,DayTimeIntervalType,TimestampType\nfrom pyspark.sql import functions as SF\n\n#Given Columns\namount = \"amount\"\nmerchant_id = \"merchant_id\"\ntransaction_id = \"tranaction_id\"\ndate_format = \"MM/dd/yyyy HH:mm:ss\"\ncredit_card_id = \"credit_card_id\"\ntransaction_timestamp = \"transaction_timestamp\"\n# Transaction Data \ntransactionData = [(1, 101, 1, 100, \"09/25/2022 12:00:00\"),(2, 101, 1, 100, \"09/25/2022 12:08:00\"),\n                  (3, 101, 1, 100, \"09/25/2022 12:28:00\"),(4, 102, 2, 300, \"09/25/2022 12:00:00\"),\n                  (6, 102, 2, 400, \"09/25/2022 14:00:00\")]\n\n \n# Schema creations\ntransactionSchema = StructType([ StructField(transaction_id, IntegerType(), True),\\\n                        StructField(merchant_id, IntegerType(), True),\\\n                        StructField(credit_card_id, IntegerType(), True),\\\n                        StructField(amount, IntegerType(), True),\\\n                        StructField(transaction_timestamp, StringType(), True)\n                      ])\n\ntransaction_df = spark.createDataFrame(data=transactionData,schema=transactionSchema)\ntimeStamp = SF.to_timestamp(SF.col(transaction_timestamp),date_format).cast(TimestampType())\ntransaction_df = transaction_df.withColumn(transaction_timestamp,timeStamp)\ntransaction_df.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2e055fb-2f3f-46b3-8345-698ac3f08a49","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+-----------+--------------+------+---------------------+\n|tranaction_id|merchant_id|credit_card_id|amount|transaction_timestamp|\n+-------------+-----------+--------------+------+---------------------+\n|            1|        101|             1|   100|  2022-09-25 12:00:00|\n|            2|        101|             1|   100|  2022-09-25 12:08:00|\n|            3|        101|             1|   100|  2022-09-25 12:28:00|\n|            4|        102|             2|   300|  2022-09-25 12:00:00|\n|            6|        102|             2|   400|  2022-09-25 14:00:00|\n+-------------+-----------+--------------+------+---------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.window import Window\n\n\ndiff_min_col = SF.col(transaction_timestamp).cast(\"long\") - SF.col(\"previous_transaction\").cast(\"long\")\n\nwindowSpec = Window.partitionBy(merchant_id,credit_card_id,amount,).orderBy(transaction_timestamp)\ntransaction_df = transaction_df.withColumn(\"previous_transaction\", SF.lag(transaction_timestamp,1).over(windowSpec))\\\n                               .withColumn(\"diff_in_minutes\",diff_min_col/60)\\\n                               .filter(SF.col(\"diff_in_minutes\") <= 10)\n\n \ntransaction_df.show()\ntransaction_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f8f1930-1359-4df9-81de-28a26546c95c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+-----------+--------------+------+---------------------+--------------------+---------------+\n|tranaction_id|merchant_id|credit_card_id|amount|transaction_timestamp|previous_transaction|diff_in_minutes|\n+-------------+-----------+--------------+------+---------------------+--------------------+---------------+\n|            2|        101|             1|   100|  2022-09-25 12:08:00| 2022-09-25 12:00:00|            8.0|\n+-------------+-----------+--------------+------+---------------------+--------------------+---------------+\n\nroot\n |-- tranaction_id: integer (nullable = true)\n |-- merchant_id: integer (nullable = true)\n |-- credit_card_id: integer (nullable = true)\n |-- amount: integer (nullable = true)\n |-- transaction_timestamp: timestamp (nullable = true)\n |-- previous_transaction: timestamp (nullable = true)\n |-- diff_in_minutes: double (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7fcbc4cd-151d-4b1b-8442-66a5492b363f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Pyspark-Question2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2399361266039433}},"nbformat":4,"nbformat_minor":0}
